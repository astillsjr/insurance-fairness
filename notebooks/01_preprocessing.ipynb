{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aaa6d6c",
   "metadata": {},
   "source": [
    "# 01: Data Preprocessing\n",
    "\n",
    "This notebook handles data preparation for the insurance claim prediction models:\n",
    "- Load and clean the dataset\n",
    "- Handle missing values and outliers\n",
    "- Encode categorical features\n",
    "- Balance the dataset (if needed)\n",
    "- Split into train/validation/test sets\n",
    "- Save processed data for downstream notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (for Google Colab)\n",
    "!pip install fairlearn seaborn -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "Path('../results').mkdir(exist_ok=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
